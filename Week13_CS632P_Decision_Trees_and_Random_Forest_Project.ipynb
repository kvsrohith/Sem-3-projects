{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F2-PiL-ud4D"
      },
      "source": [
        "##Project : # Random Forest\n",
        "\n",
        "**Answer the following questions, download the .ipynb file and submit the file.**\n",
        "* Name : \n",
        "* Sesion :\n",
        "* CRN :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQMuGPultDp9"
      },
      "source": [
        "###\n",
        "\n",
        "For this project we will be exploring publicly available data from [LendingClub.com](www.lendingclub.com). Lending Club connects people who need money (borrowers) with people who have money (investors). Hopefully, as an investor you would want to invest in people who showed a profile of having a high probability of paying you back. We will try to create a model that will help predict this.\n",
        "\n",
        "Lending club had a [very interesting year in 2016](https://en.wikipedia.org/wiki/Lending_Club#2016), so let's check out some of their data and keep the context in mind. This data is from before they even went public.\n",
        "\n",
        "We will use lending data from 2007-2010 and be trying to classify and predict whether or not the borrower paid back their loan in full. You can download the data from [here](https://www.kaggle.com/datasets/northpatawee/ficoloans/) or just use the csv already provided.\n",
        "\n",
        "Here are what the columns represent:\n",
        "* credit.policy: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.\n",
        "* purpose: The purpose of the loan (takes values \"credit_card\", \"debt_consolidation\", \"educational\", \"major_purchase\", \"small_business\", and \"all_other\").\n",
        "* int.rate: The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.\n",
        "* installment: The monthly installments owed by the borrower if the loan is funded.\n",
        "* log.annual.inc: The natural log of the self-reported annual income of the borrower.\n",
        "* dti: The debt-to-income ratio of the borrower (amount of debt divided by annual income).\n",
        "* fico: The FICO credit score of the borrower.\n",
        "* days.with.cr.line: The number of days the borrower has had a credit line.\n",
        "* revol.bal: The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).\n",
        "* revol.util: The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).\n",
        "* inq.last.6mths: The borrower's number of inquiries by creditors in the last 6 months.\n",
        "* delinq.2yrs: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n",
        "* pub.rec: The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJaKvdXAtDp_"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "**Import the usual libraries for pandas and plotting. You can import sklearn later on.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Au0jOU2HtDqB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE1MbohKtDqC"
      },
      "source": [
        "## Get the Data\n",
        "\n",
        "**Use pandas to read loan_data.csv as a dataframe called loans.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DB_Z3sSDtDqD"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('loan_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIEgHhG_tDqE"
      },
      "source": [
        "**Check out the info(), head(), and describe() methods on loans.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIUcZumOtDqF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaNapWJZtDqG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbhlaWSRtDqH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FpW0KjQtDqJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6OJRMbFtDqJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28E-TANKtDqK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhhRXz-mtDqK"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "Do some data visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA4TYr4WtDqM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dc3b82ZtDqO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyRX4QGOtDqO"
      },
      "source": [
        "**Create a countplot using seaborn showing the counts of loans by purpose, with the color hue defined by not.fully.paid.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S28g8XSGtDqP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTauZkDjtDqP"
      },
      "source": [
        "**Let's see the trend between FICO score and interest rate. Recreate the following jointplot.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkPlT7CZtDqQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuQheK4PtDqQ"
      },
      "source": [
        "**Create the following lmplots to see if the trend differed between not.fully.paid and credit.policy. Check the documentation for lmplot() if you can't figure out how to separate it into columns.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz_vPROBtDqS"
      },
      "source": [
        "# Setting up the Data\n",
        "\n",
        "Let's get ready to set up our data for our Random Forest Classification Model!\n",
        "\n",
        "**Check loans.info() again.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2vDch1HtDqS",
        "outputId": "21606f89-cc59-4015-f4ff-a7ff640c0dcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9578 entries, 0 to 9577\n",
            "Data columns (total 14 columns):\n",
            "credit.policy        9578 non-null int64\n",
            "purpose              9578 non-null object\n",
            "int.rate             9578 non-null float64\n",
            "installment          9578 non-null float64\n",
            "log.annual.inc       9578 non-null float64\n",
            "dti                  9578 non-null float64\n",
            "fico                 9578 non-null int64\n",
            "days.with.cr.line    9578 non-null float64\n",
            "revol.bal            9578 non-null int64\n",
            "revol.util           9578 non-null float64\n",
            "inq.last.6mths       9578 non-null int64\n",
            "delinq.2yrs          9578 non-null int64\n",
            "pub.rec              9578 non-null int64\n",
            "not.fully.paid       9578 non-null int64\n",
            "dtypes: float64(6), int64(7), object(1)\n",
            "memory usage: 1.0+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26nxXsfltDqT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLJYOWc_tDqT"
      },
      "source": [
        "## Categorical Features\n",
        "\n",
        "Notice that the **purpose** column as categorical\n",
        "\n",
        "That means we need to transform them using dummy variables so sklearn will be able to understand them. Let's do this in one clean step using pd.get_dummies.\n",
        "\n",
        "Let's show you a way of dealing with these columns that can be expanded to multiple categorical features if necessary.\n",
        "\n",
        "**Create a list of 1 element containing the string 'purpose'. Call this list cat_feats.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XamP-BxPtDqT"
      },
      "outputs": [],
      "source": [
        "cat_feats = ['purpose']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yyjJutiLtDqU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqwOhUostDqU"
      },
      "source": [
        "**Now use pd.get_dummies(loans,columns=cat_feats,drop_first=True) to create a fixed larger dataframe that has new feature columns with dummy variables. Set this dataframe as final_data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut8hMVXptDqU"
      },
      "outputs": [],
      "source": [
        "df_dummy = pd.get_dummies(df, columns=cat_feats, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTjX3f9VtDqV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T_-KFQltDqV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jpDT_e5tDqV"
      },
      "source": [
        "## Train Test Split\n",
        "\n",
        "Now its time to split our data into a training set and a testing set!\n",
        "\n",
        "**Use sklearn to split your data into a training set and a testing set as we've done in the past.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBtm4kRRtDqW"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fjJm53YtDqW"
      },
      "source": [
        "## Training a Decision Tree Model\n",
        "\n",
        "Let's start by training a single decision tree first!\n",
        "\n",
        "**Import DecisionTreeClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2qq44hSStDqW"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX5LyyJRtDqX"
      },
      "source": [
        "**Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujrqBf1btDqX"
      },
      "outputs": [],
      "source": [
        "dtree = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kktHIWUstDqX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AXiMYG4tDqX",
        "outputId": "0106457f-6e41-47ef-e453-e602a983e7c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
              "            max_features=None, max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
              "            splitter='best')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtree.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEU1YlU6tDqY",
        "outputId": "6f9ec487-5095-4842-da53-9640144bef24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
              "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
              "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "            presort=False, random_state=None, splitter='best')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdflu3TetDqY"
      },
      "source": [
        "## Predictions and Evaluation of Decision Tree\n",
        "**Create predictions from the test set and create a classification report and a confusion matrix.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CothfLHstDqZ"
      },
      "outputs": [],
      "source": [
        "pred_dtree = dtree.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGbDrZZXtDqZ",
        "outputId": "158809c0-1c88-4473-c7ea-9b138f5b32b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2007  424]\n",
            " [ 348   95]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, pred_dtree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nuR9hgztDqZ",
        "outputId": "ac51a56a-79f3-41df-d135-3c7f846e903f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84      2431\n",
            "           1       0.18      0.21      0.20       443\n",
            "\n",
            "   micro avg       0.73      0.73      0.73      2874\n",
            "   macro avg       0.52      0.52      0.52      2874\n",
            "weighted avg       0.75      0.73      0.74      2874\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, pred_dtree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YUS3l6KJtDqZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EhZ1uiXKtDqZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roSGtBfStDqZ",
        "outputId": "a368d4f2-e99b-4024-cd79-f916dea531f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.85      0.81      0.83      2431\n",
            "          1       0.16      0.20      0.18       443\n",
            "\n",
            "avg / total       0.74      0.72      0.73      2874\n",
            "\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVgqppc5tDqa",
        "outputId": "58e88b15-1ee5-4ae8-e4ca-97a330a05991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1980  451]\n",
            " [ 355   88]]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aorfAyvetDqa"
      },
      "source": [
        "## Training the Random Forest model\n",
        "\n",
        "Now its time to train our model!\n",
        "\n",
        "**Create an instance of the RandomForestClassifier class and fit it to our training data from the previous step.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Y-lMaFfetDqb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T1e6Tz1ktDqe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yR7U6uD6tDqf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roecAA06tDqf"
      },
      "source": [
        "## Predictions and Evaluation\n",
        "\n",
        "Let's predict off the y_test values and evaluate our model.\n",
        "\n",
        "**Predict the class of not.fully.paid for the X_test data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te8vYMtZtDqf"
      },
      "outputs": [],
      "source": [
        "rfc_pred = rfc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Bq_cA_DtDqg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K4YzSt1tDqg"
      },
      "source": [
        "**Now create a classification report from the results. Do you get anything strange or some sort of warning?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYsMFV7OtDqg",
        "outputId": "8db3b1ee-3bf3-499d-8c0d-63a9634f53e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2431    0]\n",
            " [ 443    0]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, rfc_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S6LIA0btDqg",
        "outputId": "81258bb3-700c-4276-ab05-b903749daf94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92      2431\n",
            "           1       0.00      0.00      0.00       443\n",
            "\n",
            "   micro avg       0.85      0.85      0.85      2874\n",
            "   macro avg       0.42      0.50      0.46      2874\n",
            "weighted avg       0.72      0.85      0.78      2874\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/karlo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/home/karlo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/home/karlo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, rfc_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Z1WwM-A0tDqh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zogVIg-tDqh"
      },
      "source": [
        "**Show the Confusion Matrix for the predictions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGBmIna_tDqh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZMOPAOotDqi"
      },
      "source": [
        "**What performed better the random forest or the decision tree?**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Week13 CS632P Decision Trees and Random Forest Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
